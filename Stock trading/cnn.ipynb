{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd76d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# All code was written by Derek Shore, unless otherwise noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c13fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training/test features \n",
    "training_features = pd.read_hdf('../build_dataset/aapl_spy_training_examples.h5', key='data')\n",
    "test_features = pd.read_hdf('../build_dataset/aapl_spy_test_examples.h5', key='data')\n",
    "\n",
    "training_target = pd.read_hdf('../build_dataset/aapl_spy_training_target.h5', key='data')\n",
    "test_target = pd.read_hdf('../build_dataset/aapl_spy_test_target.h5', key='data')\n",
    "\n",
    "# https://pytorch.org/docs/stable/generated/torch.eye.html\n",
    "training_target = torch.eye(3)[training_target.values]\n",
    "test_target = torch.eye(3)[test_target.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a1efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the technical indicators\n",
    "technical_keys = np.unique([i[0] for i in training_features.keys()])\n",
    "\n",
    "# Build a dictionary from the loaded training_feature DataFrame\n",
    "training_technical_dict = {}\n",
    "for technical in technical_keys:\n",
    "    training_technical_dict[technical] = training_features[technical]\n",
    "\n",
    "# Build a dictionary from the loaded test_feature DataFrame\n",
    "test_technical_dict = {}\n",
    "for technical in technical_keys:\n",
    "    test_technical_dict[technical] = test_features[technical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a93791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# of technicals : # of dates : # of stock tickers\n",
    "# original data\n",
    "#training_shape = (109, 9262, 501)\n",
    "#test_shape = (109, 1040, 501)\n",
    "\n",
    "# of technicals : # of dates : # of stock tickers\n",
    "# reduced tickers/technicals data\n",
    "training_shape = (16, 6764, 2)\n",
    "test_shape = (16, 756, 2)\n",
    "\n",
    "training_features_tensor = torch.zeros(training_shape)\n",
    "test_features_tensor = torch.zeros(test_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decf1240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.Tensor.index_copy_.html\n",
    "\n",
    "for index, key in enumerate(technical_keys): \n",
    "    training_features_tensor[index, :, :].copy_(torch.tensor(training_technical_dict[key].values)) \n",
    "    \n",
    "for index, key in enumerate(technical_keys):\n",
    "    test_features_tensor[index, :, :].copy_(torch.tensor(test_technical_dict[key].values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "176de070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the tutorial found in the PyTorch documentation\n",
    "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, stock_tensor, stock_target_labels_df, example_length):\n",
    "        self.stock_tensor = stock_tensor\n",
    "        self.example_length = example_length\n",
    "        self.stock_targets = stock_target_labels_df\n",
    "\n",
    "    def __len__(self):\n",
    "        # The number of examples in the stock dataset\n",
    "        return self.stock_tensor.shape[1] - self.example_length + 1\n",
    "\n",
    "    def __getitem__(self, this_index):\n",
    "        start_index = this_index\n",
    "        end_index = this_index + self.example_length\n",
    "        \n",
    "        # I'm doing the transpose here so that the dimensionality goes: \n",
    "        # number of features : # of stocks : # of dates\n",
    "        features = self.stock_tensor[:,start_index:end_index,:].clone().detach().transpose(1,2)\n",
    "        label = torch.squeeze(self.stock_targets[this_index].clone().detach(), -1)\n",
    "\n",
    "        return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d328d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7581173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Based on the tutorial found in the PyTorch documentation\n",
    "# # https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "class StockCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StockCNN, self).__init__()\n",
    "        \n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "        self.this_conv1 = nn.Conv2d(16, 32, kernel_size=2, padding=2)\n",
    "        self.this_conv2 = nn.Conv2d(32, 32, kernel_size=2, padding=2)\n",
    "        \n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n",
    "        self.this_relu1 = nn.ReLU()\n",
    "        self.this_relu2 = nn.ReLU()\n",
    "        self.this_relu3 = nn.ReLU()\n",
    "        \n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
    "        self.this_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.this_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "        self.this_linear1 = nn.Linear(320, 224)\n",
    "        self.this_linear2 = nn.Linear(224, 3)\n",
    "            \n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html\n",
    "        self.this_softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, this_features):\n",
    "        #print(this_features.shape)\n",
    "        this_features = self.this_conv1(this_features)\n",
    "        this_features = self.this_relu1(this_features)\n",
    "        this_features = self.this_pool1(this_features)\n",
    "        \n",
    "        this_features = self.this_conv2(this_features)\n",
    "        this_features = self.this_relu2(this_features)\n",
    "        this_features = self.this_pool2(this_features)\n",
    "\n",
    "        this_features = this_features.view(-1, this_features.shape[1] * this_features.shape[2] * this_features.shape[3])\n",
    "\n",
    "        this_features = self.this_linear1(this_features)\n",
    "        this_features = self.this_relu3(this_features)\n",
    "        \n",
    "        this_features = self.this_linear2(this_features)\n",
    "        this_features = self.this_softmax(this_features)\n",
    "        \n",
    "        return this_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc0ec61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the tutorial found in the PyTorch documentation\n",
    "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "stock_training_dataset = StockDataset(training_features_tensor, training_target, 14)\n",
    "stock_test_dataset = StockDataset(test_features_tensor, test_target, 14)\n",
    "\n",
    "stock_training_dataloader = DataLoader(stock_training_dataset, batch_size=batch_size, shuffle=True)\n",
    "stock_test_dataloader = DataLoader(stock_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "507c7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "\n",
    "def train(stock_training_dataloader, stock_model, loss_fn, optimizer):\n",
    "    size = len(stock_training_dataloader.dataset)\n",
    "    \n",
    "    average_loss = 0\n",
    "    average_accuracy = 0\n",
    "    \n",
    "    predictions = []\n",
    "\n",
    "    for batch, (features, targets) in enumerate(stock_training_dataloader):\n",
    "        features, targets = features.to(device), targets.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = stock_model(features)\n",
    "        loss = loss_fn(pred.view(-1), targets.view(-1))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss = loss.item() * len(pred) / size\n",
    "        average_loss += loss\n",
    "        \n",
    "        pred_indices = torch.argmax(pred.cpu(), dim=1)\n",
    "        predictions.append(pred_indices.tolist())\n",
    "        real_indices = torch.argmax(targets.reshape(pred.shape[0],3).cpu(), dim=1)\n",
    "        this_accuracy = sum(pred_indices == real_indices)/len(real_indices)\n",
    "        \n",
    "        average_accuracy += this_accuracy.item() * len(pred) / size\n",
    "\n",
    "    return average_loss, average_accuracy, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c717223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(stock_test_dataloader, stock_model, loss_fn):\n",
    "    size = len(stock_test_dataloader.dataset)\n",
    "\n",
    "    average_loss = 0\n",
    "    average_accuracy = 0\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for batch, (features, targets) in enumerate(stock_test_dataloader):\n",
    "        features, targets = features.to(device), targets.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = stock_model(features)\n",
    "        loss = loss_fn(pred.view(-1), targets.view(-1))\n",
    "\n",
    "        loss = loss.item() * len(pred) / size\n",
    "        average_loss += loss\n",
    "        \n",
    "        pred_indices = torch.argmax(pred.cpu(), dim=1)\n",
    "        predictions.append(pred_indices.tolist())\n",
    "        real_indices = torch.argmax(targets.reshape(pred.shape[0],3).cpu(), dim=1)\n",
    "        this_accuracy = sum(pred_indices == real_indices)/len(real_indices)\n",
    "        \n",
    "        average_accuracy += this_accuracy.item() * len(pred) / size\n",
    "        \n",
    "    return average_loss, average_accuracy, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35f2854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was originally created by Rocco\n",
    "# Modified for application to CNNs by Derek\n",
    "\n",
    "def rolling_window_cv(batch_size=64, lr=1e-4, num_folds=5, epochs=10, device='mps'):\n",
    "    train_data_size = len(stock_training_dataset)\n",
    "    n = train_data_size // num_folds\n",
    "    validation_errors = []\n",
    "    \n",
    "    training_losses = np.zeros([num_folds, epochs])\n",
    "    training_accuracies = np.zeros([num_folds, epochs])\n",
    "    \n",
    "    val_losses = np.zeros([num_folds, epochs])\n",
    "    val_accuracies = np.zeros([num_folds, epochs])\n",
    "\n",
    "    for fold in range(num_folds):\n",
    "        print(f\"Fold {fold+1} of {num_folds}\")\n",
    "\n",
    "        start_idx = fold * n\n",
    "        end_idx = (fold + 1) * n\n",
    "\n",
    "        k_train_data_fold_indices = list(range(0, start_idx)) + list(range(end_idx, train_data_size))\n",
    "        \n",
    "        # https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset\n",
    "        train_data_fold = torch.utils.data.Subset(stock_training_dataset, k_train_data_fold_indices)\n",
    "        val_data_fold = torch.utils.data.Subset(stock_training_dataset, range(start_idx, end_idx))\n",
    "\n",
    "        training_dataloader = DataLoader(train_data_fold, batch_size=batch_size, shuffle=True)\n",
    "        val_dataloader = DataLoader(val_data_fold, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Fresh model and optimizer for each fold\n",
    "        model = StockCNN().to(device)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        fold_losses = []\n",
    "        fold_accuarcies = []\n",
    "        \n",
    "        fold_val_losses = []\n",
    "        fold_val_accuarcies = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_losses, epoch_accuracies = train(training_dataloader, model, loss_fn, optimizer)\n",
    "            fold_losses.append(epoch_losses)\n",
    "            fold_accuarcies.append(epoch_accuracies)\n",
    "            \n",
    "            this_val_losses, this_val_accuracies = test(val_dataloader, model, loss_fn)\n",
    "            fold_val_losses.append(this_val_losses)\n",
    "            fold_val_accuarcies.append(this_val_accuracies)\n",
    "       \n",
    "        training_losses[fold] = fold_losses\n",
    "        training_accuracies[fold] = fold_accuarcies\n",
    "        \n",
    "        val_losses[fold] = fold_val_losses\n",
    "        val_accuracies[fold] = fold_val_accuarcies\n",
    "    \n",
    "    \n",
    "    print(\"Average Training Losses\")\n",
    "    final_training_losses = np.round(training_losses.mean(axis=0),2)\n",
    "    print(final_training_losses)\n",
    "    print()\n",
    "    \n",
    "    print(\"Average Training Accuracy:\")\n",
    "    final_training_accuracies = np.round(training_accuracies.mean(axis=0),2)\n",
    "    print(final_training_accuracies)\n",
    "    print()\n",
    "    \n",
    "    print(\"Validation Losses:\")\n",
    "    final_val_losses = np.round(val_losses.mean(axis=0),2)\n",
    "    print(final_val_losses)\n",
    "    print()\n",
    "    \n",
    "    print(\"Validation Accuracy:\")\n",
    "    final_val_accuracies = np.round(val_accuracies.mean(axis=0),2)\n",
    "    print(final_val_accuracies)\n",
    "    print()\n",
    "    \n",
    "    return final_training_losses, final_training_accuracies, final_val_losses, final_val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd6addf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 µs, sys: 2 µs, total: 24 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#final_training_losses1, final_training_accuracies1, \\\n",
    "#           final_val_losses1, final_val_accuracies1 = rolling_window_cv(batch_size=32, lr=1e-4, num_folds=5, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a34c64c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1 µs, total: 2 µs\n",
      "Wall time: 4.29 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#final_training_losses2, final_training_accuracies2, \\\n",
    "#           final_val_losses2, final_val_accuracies2 = rolling_window_cv(batch_size=64, lr=1e-4, num_folds=5, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7623c6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 µs, sys: 2 µs, total: 26 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#final_training_losses3, final_training_accuracies3, \\\n",
    "#          final_val_losses3, final_val_accuracies3 = rolling_window_cv(batch_size=128, lr=1e-4, num_folds=5, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf69de37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 2 µs, total: 12 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#final_training_losses4, final_training_accuracies4, \\\n",
    "#           final_val_losses4, final_val_accuracies4 = rolling_window_cv(batch_size=256, lr=1e-4, num_folds=5, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "317ec13f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_nums = range(1,51)\n",
    "\n",
    "# plt.plot(epoch_nums, final_val_accuracies1, label = 'BS = 32')\n",
    "# plt.plot(epoch_nums, final_val_accuracies2, label = 'BS = 64')\n",
    "# plt.plot(epoch_nums, final_val_accuracies3, label = 'BS = 128')\n",
    "# plt.plot(epoch_nums, final_val_accuracies4, label = 'BS = 256')\n",
    "\n",
    "# plt.xlabel('Epoch #')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Validation Accuracy as a Function of Batch Size (BS)')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the graph\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "409282cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 µs, sys: 1 µs, total: 14 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#final_training_losses5, final_training_accuracies5, \\\n",
    "#           final_val_losses5, final_val_accuracies5 = rolling_window_cv(batch_size=64, lr=1e-5, num_folds=5, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5834f992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33 µs, sys: 1 µs, total: 34 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#final_training_losses6, final_training_accuracies6, \\\n",
    "#           final_val_losses6, final_val_accuracies6 = rolling_window_cv(batch_size=64, lr=1e-4, num_folds=5, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82132f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 µs, sys: 1e+03 ns, total: 23 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#final_training_losses7, final_training_accuracies7, \\\n",
    "#           final_val_losses7, final_val_accuracies7 = rolling_window_cv(batch_size=64, lr=1e-3, num_folds=5, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3979ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 1 µs, total: 13 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#final_training_losses8, final_training_accuracies8, \\\n",
    "#           final_val_losses8, final_val_accuracies8 = rolling_window_cv(batch_size=64, lr=1e-2, num_folds=5, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcc3b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_nums = range(1,51)\n",
    "\n",
    "# plt.plot(epoch_nums, final_val_accuracies5, label = 'LR = 1e-5')\n",
    "# plt.plot(epoch_nums, final_val_accuracies6, label = 'LR = 1e-4')\n",
    "# plt.plot(epoch_nums, final_val_accuracies7, label = 'LR = 1e-3')\n",
    "# plt.plot(epoch_nums, final_val_accuracies8, label = 'LR = 1e-2')\n",
    "\n",
    "# plt.xlabel('Epoch #')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Validation Accuracy as a Function of Learning Rate (LR)')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the graph\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8eea82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_nums = range(1,51)\n",
    "\n",
    "# plt.plot(epoch_nums, final_training_accuracies2, label = 'Training')\n",
    "# plt.plot(epoch_nums, final_val_accuracies2, label = 'Validation')\n",
    "\n",
    "\n",
    "# plt.xlabel('Epoch #')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy as a Function of Training Epochs')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the graph\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "222919a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_model = StockCNN().to(device)\n",
    "\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# https://pytorch.org/docs/stable/generated/torch.optim.SGD.html\n",
    "optimizer = torch.optim.SGD(stock_model.parameters(), lr=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7a917c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # : Accuracy\n",
      "Epoch 1 : 0.32\n",
      "Epoch 2 : 0.34\n",
      "Epoch 3 : 0.36\n",
      "Epoch 4 : 0.41\n",
      "Epoch 5 : 0.42\n",
      "Epoch 6 : 0.44\n",
      "Epoch 7 : 0.44\n",
      "Epoch 8 : 0.45\n",
      "Epoch 9 : 0.47\n",
      "Epoch 10 : 0.51\n",
      "Epoch 11 : 0.58\n",
      "Epoch 12 : 0.66\n",
      "Epoch 13 : 0.74\n",
      "Epoch 14 : 0.81\n",
      "Epoch 15 : 0.84\n",
      "Epoch 16 : 0.87\n",
      "Epoch 17 : 0.88\n",
      "Epoch 18 : 0.9\n",
      "Epoch 19 : 0.91\n",
      "Epoch 20 : 0.92\n",
      "Epoch 21 : 0.92\n",
      "Epoch 22 : 0.92\n",
      "Epoch 23 : 0.93\n",
      "Epoch 24 : 0.94\n",
      "Epoch 25 : 0.93\n",
      "Epoch 26 : 0.94\n",
      "Epoch 27 : 0.95\n",
      "Epoch 28 : 0.94\n",
      "Epoch 29 : 0.95\n",
      "Epoch 30 : 0.95\n",
      "Epoch 31 : 0.95\n",
      "Epoch 32 : 0.95\n",
      "Epoch 33 : 0.96\n",
      "Epoch 34 : 0.95\n",
      "Epoch 35 : 0.96\n",
      "Epoch 36 : 0.97\n",
      "Epoch 37 : 0.97\n",
      "Epoch 38 : 0.96\n",
      "Epoch 39 : 0.96\n",
      "Epoch 40 : 0.96\n",
      "[335.4705205032198, 335.3450369322817, 335.1996691475937, 335.0244214805633, 334.8273638551666, 334.57524926410633, 334.2715515421508, 333.9279786557591, 333.4283472580162, 332.5927052442065, 330.23929276012194, 324.59511293465783, 319.2321452549205, 314.99724333509835, 312.3035818785672, 310.3721405976332, 309.12572827887993, 308.0424155753871, 307.3358273930662, 306.637414938184, 306.30496076590345, 306.23482852913753, 305.6849449653835, 305.2359630012314, 305.2832215526266, 304.88635559375865, 304.693875488679, 304.55828053459305, 304.2209696011832, 304.56580122692134, 304.04190241808436, 303.99908199883845, 303.9480977522463, 303.9602145055297, 303.43675408909337, 303.376080017587, 303.08265157820216, 303.39039694766706, 303.23211949963945, 303.1987310722306]\n",
      "\n",
      "[0.32187824022538597, 0.33920900603344356, 0.35890979108907867, 0.4071989334295314, 0.41712338906573343, 0.435491038298469, 0.44245296986857746, 0.44793363939460257, 0.47415197741418463, 0.5061472373668429, 0.5797659606425748, 0.6599022366173835, 0.7421122796887596, 0.8066953044258354, 0.841504962104212, 0.8724633386321918, 0.8822396680825273, 0.9010516960715175, 0.9087542584959161, 0.9188268404769075, 0.9246037624143981, 0.9217893645562447, 0.9300844318124032, 0.9358613537498942, 0.9339357132453281, 0.9417864018909099, 0.9451933047132584, 0.9446007998814993, 0.9524514885359104, 0.9460820617843179, 0.9545252555265301, 0.9546733817300558, 0.9558583912169946, 0.9524514885359101, 0.9614871870922245, 0.9656347206496715, 0.9684491185254832, 0.9614871869509598, 0.9638572063398014, 0.964597837357429]\n",
      "[328.6174304289581, 328.59210287225034, 328.5452497027925, 328.4651062093866, 328.38081517996085, 328.299156137623, 328.2678938566595, 328.24260620281484, 328.3249480502923, 328.5604562669551, 329.26570143770243, 331.03377199237144, 331.6258697509766, 332.78409027058535, 333.2210533788996, 333.8064824100458, 334.04468455256875, 334.30716307936575, 334.8949999392113, 334.85128554168324, 334.89167606974996, 334.5191209877804, 335.25046343180895, 335.18276957002337, 335.339590388384, 335.2536547572263, 335.294273633174, 335.5372738331195, 335.3451449367272, 334.90988851267434, 334.7497976310802, 335.24045927271067, 335.0120886780853, 335.58911494258916, 335.32783265967396, 335.3749982749149, 335.0906326889511, 335.4097005810744, 334.9182546623302, 335.30106718286686]\n",
      "\n",
      "[0.3109017502651882, 0.3162853303459419, 0.3606998657714952, 0.37146702609344573, 0.38088829131498636, 0.3768506064148642, 0.38358008127514154, 0.37415881629426584, 0.3553162860116279, 0.3472409159707189, 0.343203230829932, 0.3647375507518389, 0.356662180871373, 0.3351278604681367, 0.3405114405488904, 0.3337819656083914, 0.33378196544794825, 0.3297442805478262, 0.3270524902667845, 0.33378196536772664, 0.3324360703475382, 0.344549125529234, 0.32570659532681767, 0.33109017532734974, 0.32705249018656296, 0.32839838528697296, 0.3270524903470061, 0.33109017532734974, 0.3324360704277598, 0.33512786054835825, 0.33916554560892354, 0.34051144046866877, 0.34320323050904555, 0.3283983852869729, 0.33109017532734974, 0.3364737554081034, 0.3378196505085135, 0.3337819652875051, 0.3405114405488904, 0.33512786046813664]\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "predictions = None\n",
    "print(\"Epoch # : Accuracy\")\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    this_loss, this_accuracy, predictions = train(stock_training_dataloader, stock_model, loss_fn, optimizer)\n",
    "    epoch_losses.append(this_loss)\n",
    "    epoch_accuracies.append(this_accuracy)\n",
    "    print(\"Epoch\", str(epoch + 1), \":\", str(np.round(this_accuracy, 2)))\n",
    "    test_epoch_losses, test_epoch_accuracies, _ = test(stock_test_dataloader, stock_model, loss_fn)\n",
    "    test_losses.append(test_epoch_losses)\n",
    "    test_accuracies.append(test_epoch_accuracies)\n",
    "    \n",
    "print(epoch_losses)\n",
    "print()\n",
    "print(epoch_accuracies)\n",
    "#print(predictions)\n",
    "print(test_losses)\n",
    "print()\n",
    "print(test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7932b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(epoch_losses).to_csv('training_losses_4_report.csv')\n",
    "pd.DataFrame(epoch_accuracies).to_csv('training_accuracies_4_report.csv')\n",
    "pd.DataFrame(test_losses).to_csv('test_losses_4_report.csv')\n",
    "pd.DataFrame(test_accuracies).to_csv('test_accuracies_4_report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e84265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "\n",
    "for i in predictions:\n",
    "    for j in i:\n",
    "        pred_list.append(j)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d22fe5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_target = pd.read_hdf('../build_dataset/aapl_spy_training_target.h5', key='data')\n",
    "test_target = pd.read_hdf('../build_dataset/aapl_spy_test_target.h5', key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "865f8376",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(pred_list) - 1).to_csv('cnn_training_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87aedb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(epoch_accuracies, index = range(1,len(epoch_accuracies)+1)).to_csv('cnn_training_accuracies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fed1cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_loss, average_accuracy, predictions = test(stock_test_dataloader, stock_model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "029a1378",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "\n",
    "for i in predictions:\n",
    "    for j in i:\n",
    "        pred_list.append(j)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb606412",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(pred_list) - 1).to_csv('cnn_test_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adc4a8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35262449540969976"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
